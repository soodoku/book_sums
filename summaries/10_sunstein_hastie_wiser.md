## Wiser

**Note:** Though there is some mention of statistical groups, the book is mostly about "deliberating groups." And by deliberating groups, S/H mean any group in which people talk. They don't distinguish between a group composed of a boss and underlings, a jury, and a Deliberative Poll (random sample, trained moderators, no pressure of losing yr. job, etc.).

I have extensively reorganized the material to make the logic clearer---the book is woefully disorganized. The new outline = individuals got problems. There are some reasons to think why groups where people talk with each other may do better (worse). What do we find? How do we make group decision making better? How do we leverage groups of people more generally?

### Individual Psych. Biases:

* Availability
   - Familiarity
   - Salience (terrorist attack)
     - (Slovic - Perception of risk)
     - Whether people buy insurance for natural disaster affected by recent experiences
   - People tend to think more words on a page will end with 'ing' than with n in the second last place. Words ending with ing are easier to recall.
* Representativeness
   - Extent to which A looks like B
   - Looks like a good CEO, candidate
   - Causes resemble their effects (Rozin and Nemeroff)
* Framing
   - Save \$600 versus lose \$600 per year
* Egocentric biases
   * Other people think and act as we do
* Unrealistic optimism
* Overconfidence
   - Planning Fallacy
   - Thinking you are better than others: 
     - 90% of drivers believe that they are above average
   - Overprecision:
     - narrow confidence intervals
* Ignore the long term
* Unduly afraid of losses
* Self-serving judgments
* Hindsight bias
  - I knew it all along
* Sunk cost fallacy
* Anchoring

### Why Deliberating Groups May be Better?

* Information aggregation: 
  * even the greatest expert doesn't know everything. Pooling of info.
* Diversity of perspectives can cause people to think carefully, overcome their biases.

### Why Deliberating Groups May be Worse?

* People fail to disclose what they know because of:

  * information signal: 
    * if a prominent person is saying x, maybe x is correct
    * if most people make the same errors (~ social proof), maybe they are not errors at all. such deference may happen especially if the answer is somewhat debatable.
    * data: 
      * "The study involved twelve hundred people, forming groups of six, five, and four members. Individuals were asked true-false questions involving art, poetry, public opinion, geography, economics, and politics. They were then asked to assemble into groups that discussed the questions and produced answers. The views of the majority played a dominant role in determining each group’s answers; people tended to go along with what most people thought. The truth played a role, too, but a lesser one. If a majority of individuals in the group gave the right answer, the group’s decision moved toward the majority in 79 percent of the cases. If a majority of individuals in the group gave the wrong answer, the group’s decision nonetheless moved toward the majority in 56 percent of the cases. The truth did have an influence—79 percent is higher than 56 percent—but the majority’s judgment was the dominant one."
        * Thorndike, 1938. https://www.tandfonline.com/doi/abs/10.1080/00224545.1938.9920036?journalCode=vsoc20
      * "The results from Experiment 1 revealed that, for false statements, collective opinion had little influence on people’s true-false judgments, but, for true and debatable statements, their judgments were biased toward collective opinion."
        * Huaye Li and Yasuaki  Sakamoto. https://mindmodeling.org/cogsci2013/papers/0516/paper0516.pdf
      * Salganik and Watts: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3785310/
      * Lorenz. et al. "... we demonstrate by experimental evidence (*N* = 144) that even mild social influence can undermine the wisdom of crowd effect in simple estimation tasks. In the experiment, subjects could reconsider their response to factual questions after having received average or full information of the responses of other subjects." http://www.pnas.org/content/108/22/9020
  * social incentives: 
    * to avoid penalties: disapproval, displeasure from boss, etc. 
  * personal incentives:
    * I support x but also have information that is not conducive to x
      * data: one mock jury delib. of 500 --- people almost never shared info. that contradicted their current preferred verdict 

  **Conditioning factors for disclosing info. and deference to others** 

   - low status people less likely to speak up---greater deference to information signal and feel more social pressure
   - complacent people are more likely to defer to group

#### (Intermediate) Consequences of Failing to Disclose Info.

*  Focus on shared information (stuff most people in the group already know)
    - don't consider unshared info. enough

#### Effect of Failing to Disclose Info. And Deferring to Others on Group Judgment

* Greater belief in incorrect thing or more people believing the incorrect thing (what S/H call 'Amplification of errors'):

    * If you are deferring to leader's incorrect opinion or if the information signal is problematic. See above for examples.

    * an example of that is **happy talk**: leaders say everything is great. no one wants to be a bad news bear.

    * Data:

        * Salganik and Watts on pop. of songs: "We found that most songs experienced self-fulfilling prophecies, in which perceived—but initially false—popularity became real over time." https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3785310/

        * Muchnik et al. "Whereas negative social influence inspired users to correct manipulated ratings, positive social influence increased the likelihood of positive ratings by 32% and created accumulating positive herding that increased final ratings by 25% on average. " http://science.sciencemag.org/content/341/6146/647

        *  Lorenz. et al. "(*N* = 144) ... In the experiment, subjects could reconsider their response to factual questions after having received average or full information of the responses of other subjects. (S/H: people were paid for correct.) We compare subjects’ convergence of estimates and improvements in accuracy over five consecutive estimation periods with a control condition, in which no information about others’ responses was provided. Although groups are initially “wise,” knowledge about estimates of others narrows the diversity of opinions to such an extent that it undermines the wisdom of crowd effect in three different ways. The “social influence effect” diminishes the diversity of the crowd without improvements of its collective error. The “range reduction effect” moves the position of the truth to peripheral regions of the range of estimates so that the crowd becomes less reliable in providing expertise for external observers. The “confidence effect” boosts individuals’ confidence after convergence of their estimates despite lack of improved accuracy." http://www.pnas.org/content/108/22/9020

        *  Urn experiment. People paid for correct ans.

            *  Anderson and Holt, replicated by Willinger and Ziegelmeyer

                https://link.springer.com/chapter/10.1007/978-3-642-72260-8_14

### Performance of Deliberating Groups

* **Baseline to judge against:** 
    * Deliberating Group should be at least as good as the best member: 
        * group recognizes and defers to the best member
        * Or the best member makes the best argument(s) that convinces everyone
    * At least good as a statistical group
    * It should be at least as good as sum of info. everyone has
* **Worse**
  - worse in Planning fallacy
  - worse in representativeness (Stasser and Dietz-Uhler)
  - worse in overconfidence (Sniezek and Henry)
  - more vulnerable to framing (Kerr, MacCoun, Kramer)
  - more affected by spurious arguments (Schumann and Thompson)
  - more susceptible to sunk cost fallacy (Whyte - escalating commitment to...)
  - When questions have def. correct answer, do as well as or better than average but not as good as the best (Gigone and Hastie, 1997)
 * **Better**
    - slightly lower levels of availability (stasson - group consensus processes..)
    	- reduce tendency to anchor on salient numbers
    	- reduce hindsight and egocentric biases

## How to make deliberating groups better?

* Assign a leader whose job it is to get data and perspectives from people
* Anxious leaders:
  - Ask what could go wrong
  - Say what they think, say what they fear
  - example of such a person: Nancy Ann DeParle
  - anxiety causes groups to focus
* Leaders w/ greater social sensitivity
* Split decision making into 2 stages:
    - list all possible solutions (creative, divergent thinking stage)
    - select the best solution (critical thinking)
* Assign roles to people so that important perspectives are not missed
* Structure group discussion using a larger paradigm like cost-benefit analysis. 

### Performance of Statistical Groups

* "...asked college students to estimate the temperature of a classroom.10 Individual judgments ranged from 60 degrees to 85 degrees; the statistical judgment of the group was 72.4 degrees, very close to the actual temperature"
  * Hazel Knight: guess temperature (average better than 80% of individuals)
* "In one such experiment, a group of fifty-six students was asked about a jar containing 850 beans ...group estimate was 871, more accurate than that of all but one of the students."
  * Surowiecki
* "The ox weighed 1,198 pounds; the estimate, from the 787 contestants, was 1,197 pounds, more accurate than any indiv. guess"
  * Galton

### Misc. Info.

* Groupthink according to Janis Irving:  common in cohesive groups, highly directive leadership, and insulated from experts - turns out he is wrong
* apparently v. good as a leader










